{"cells": [{"cell_type": "markdown", "id": "7bfc6212-9c4d-48d0-ac13-7c01be82c7ad", "metadata": {}, "source": ["# Model quality assesment\n", "\n", "When building a statistical model, a typical question that may raise is \"how does my model compare to another one?\", or put in another way, \"How to assess the quality of my model?\". Such question is crucial when it comes to choose hyperparameters values (e.g., amount of POIs vs numbers of projection dimension) or to see if a bigger training complexity can lead to substancial improvement of the attack taking into account the time and memory complexity of one evaluator's setup. in this Section, we will try to tackle the issue following two different approach: the information theory metric computation and the rank estimation. "]}, {"cell_type": "markdown", "id": "5814062a-aede-45f8-91f0-32d1df0fdbf9", "metadata": {}, "source": ["## Information Theory Metric \n", "\n", "Information Theory (IT) metric can help us to evaluate the quality of a model. In particular, the Mutual Information (MI) between a sensitive intermediate variable and the practical leakage can be used to link the attack data complexity to its success rate, as detailed in Section 3.2.1 of the book. Intuitively, the more the leakage contains information about the targeted intermediate variable, the less traces are required to succeed. The MI is computed as follows:\n", "\n", "$$\\mathsf{MI}(V; \\boldsymbol{L}) = \\mathsf{H}(V) + \\sum_{v\\in V} \\mathsf{Pr}(v)\\cdot \\int_{l\\in L}\\mathsf{f}(\\boldsymbol{l}|v)\\cdot \\mathsf{log}_2\\mathsf{Pr}(v|\\boldsymbol{l})dl$$\n", "\n", "where $\\mathsf{H}(V)$ is the entropy of $V$ and $\\mathsf{Pr}(v|\\boldsymbol{l})$ can be computed thanks to Bayes law. However, as pointed out in Section 3.3.1, evaluating the exact MI turns out to be difficult since the true distribution of the leakage is unknown. Alternatively, we can estimate the amount of information that can be extracted from a given model using the Perceived Information (PI) and compare different models by comparing their PIs. PI is defined similarly to the MI with the difference that the value depending on the true leakage distribution are estimated, leading to its approximation given by \n", "\n", "$$\\tilde{\\mathsf{PI}}(V; \\boldsymbol{L}) = \\mathsf{H}(V) + \\sum_{v\\in V} \\mathsf{Pr}(v) \\cdot \\sum_{\\boldsymbol{l}\\in \\mathcal{L}_{t}(v)} \\dfrac{1}{\\left| \\mathcal{L}_t(v) \\right|} \\cdot \\mathsf{log}_2 \\hat{\\mathsf{Pr}}(v|\\boldsymbol{l}) dl$$\n", "\n", "where the hat notation is used to reflect the (potentially imperfect) estimation of the model, the tilde notation is used to reflect the estimation of the PI metric based on a set of test samples $\\mathcal{L}_{\\mathsf{t}}$, which is different from the set $\\mathcal{L}_{\\mathsf{p}}$ used for profiling."]}, {"cell_type": "markdown", "id": "3640138c-0d1a-4281-8feb-4b5c8e21ac8d", "metadata": {}, "source": ["Next, you first have to implement the following function that compute the $\\mathsf{PI}$. \n", "\n", "- *hint: The entropy of a uniformly distributed variable of n-bits equals n*"]}, {"cell_type": "code", "execution_count": 1, "id": "89dafc3b-852e-460a-b381-0eb0211e715b", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "def compute_PI(labels, log2prob):\n", "    \"\"\"\n", "    labels: for each traces, the correct labels associated to each variables, as an arrya of shape (ntraces, nvars)\n", "    log2prob: for each variable, for each each traces, the log-probability of each class as an array of shape (nvars, ntraces, 256)\n", "\n", "    returns: (pis, lprobs) where:\n", "        pis: for each variable, the PI value computed, as an arrya of shape (nvars, )\n", "        lprobs: for each variables, the lprob used in the pis computation for each trace (nvars, test_ntraces)\n", "    \"\"\"\n"]}, {"cell_type": "markdown", "id": "12dfbcfb-e7a8-4b0d-ba75-e603c648a936", "metadata": {}, "source": ["Next, we provide you with the following functions for calculating PI for the univariate and multivariate Gaussian templates from the previous session. Feel free to browse through them to understand what's being done. "]}, {"cell_type": "code", "execution_count": 2, "id": "f9722b3a-4f16-4539-95c4-a83921807a92", "metadata": {}, "outputs": [], "source": ["from utils_scale import utils_ta\n", "import numpy as np\n", "\n", "def univariate_model_log2prob(traces, labels, pois, models):\n", "    \"\"\"\n", "    traces: the training traces, as an array of shape (ntraces, nsamples).\n", "    labels: for each traces, the correct labels associated to each variables, as an arrya of shape (ntraces, nvars)\n", "    pois: the list of pois to used, as an array of shape (nvars, )\n", "    models: (us, ss) such as \n", "        us: the models means for each class, as an array of shape (nvars, 256)\n", "        ss: the models stds for each class, as an array of shape (nvars, 256)\n", "\n", "    return: for each variable, for each each traces, the log-probability of each class as an array of shape (nvars, ntraces, 256)\n", "    \"\"\"\n", "    return utils_ta.log2Pr_class(traces[:, pois], models)\n", "\n", "def pi_uni_TA(train_trs, train_labels, test_trs, test_labels):\n", "    \"\"\"\n", "    train_trs: the training traces as an array of shape (train_ntraces, nsamples)\n", "    train_labels: training labels (train_ntraces, nvars)\n", "    test_trs: the training traces as an array of shape (test_ntraces, nsamples)\n", "    test_labels: test labels (test_ntraces, nvars)\n", "    return: (pis, lprobs) where\n", "        - `pis` is a vector of shape (nvars,) containing the PI computed for each variable\n", "        - `lprobas` is a matrix of shape (nvars, test_ntraces) containing the log2 proba used to compute the PI\n", "    \"\"\"\n", "    # SNR \n", "    pois = utils_ta.POI_selection_SNR(train_trs, train_labels, 256)\n", "    # Compute the models\n", "    models_uni = utils_ta.univariate_gaussian_models(train_trs, train_labels, pois[:,0])\n", "    # Compute the log2prob\n", "    log2prob = univariate_model_log2prob(test_trs, test_labels, pois[:,0], models_uni)\n", "    # Compute the PI\n", "    return compute_PI(test_labels, log2prob)"]}, {"cell_type": "code", "execution_count": 3, "id": "b12cb307-736b-4bcd-b645-73dd9d03ed49", "metadata": {}, "outputs": [], "source": ["from utils_scale import utils_ta\n", "import numpy as np\n", "def multivariate_model_log2prob(traces, labels, models):\n", "    \"\"\"\n", "    traces: the training traces, as an array of shape (ntraces, nsamples).\n", "    labels: for each traces, the correct labels associated to each variables, as an arrya of shape (ntraces, nvars)\n", "    models: the 'Lda' instance build with 'multivariate_gaussian_models'\n", "    \n", "    return: for each variable, for each each traces, the log-probability of each class as an array of shape (nvars, ntraces, 256)\n", "    \"\"\"\n", "    return np.log2(models.predict_proba(traces.astype(np.int16)))\n", "\n", "def pi_LDA_multi_TA(train_trs, train_labels, test_trs, test_labels, npois, ndim):\n", "    \"\"\"\n", "    train_trs: the training traces as an array of shape (train_ntraces, nsamples)\n", "    train_labels: training labels (train_ntraces, nvars)\n", "    test_trs: the training traces as an array of shape (test_ntraces, nsamples)\n", "    test_labels: test labels (test_ntraces, nvars)\n", "    npois: amount of pois used by the LDA\n", "    ndim: amount of dimensions of the linear subspace projection. \n", "    test_labels: test labels (test_ntraces, nvars)\n", "    return: (pis, lprobs) where\n", "        - `pis` is a vector of shape (nvars,) containing the PI computed for each variable\n", "        - `lprobas` is a matrix of shape (nvars, test_ntraces) containing the log2 proba used to compute the PI\n", "    \"\"\"\n", "    # SNR \n", "    pois = utils_ta.POI_selection_SNR(train_trs, train_labels, 256)\n", "    # Compute the models\n", "    if npois==1:\n", "        upois = pois[:, :npois][:,np.newaxis]\n", "    else:\n", "        upois = pois[:,:npois]\n", "    models = utils_ta.multivariate_gaussian_models(train_trs, train_labels, upois, ndim)\n", "    # Compute the log2prob\n", "    log2prob = multivariate_model_log2prob(test_trs, test_labels, models)\n", "    # Compute the PI\n", "    return compute_PI(test_labels, log2prob)"]}, {"cell_type": "markdown", "id": "96bbf7fb-5d6a-4ecf-8421-4dc4f2990d6f", "metadata": {}, "source": ["The code below is your first tool in this session. Its main function is to calculate and display the PI values obtained as a function of the profiling complexity used to build the univariate and multivariate Gaussian models you manipulated in the previous session. In more detail, it includes the following parameters:\n", "\n", "- `qt_s`: a list containing the profiling complexities for which to compute the PI\n", "- `npois`: amount of POIs used to fit the LDA (multivariate template only)\n", "- `ndim`: amount of dimension in the linear subspace (multivariate template only)\n", "- `amount_test_traces`: amount of traces used to estimate the PI.\n", "\n", "Try to play with the values of the parameter to see their impact."]}, {"cell_type": "code", "execution_count": 4, "id": "d77513c8-09d8-49dd-85ea-6bdf930f01ad", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "from utils_scale import utils_files, utils_aes, test_scale\n", "# TODO: modify here\n", "# MTA LDA parameters \n", "npois = 2 \n", "ndim = 1 \n", "\n", "# Training complexity to consider in the PI plot generation\n", "qt_s = [3500, 4096, 6144, 7168, 8192, 14000]\n", "\n", "# Amount of traces to use for the PI estimation\n", "amount_test_traces = 2048 # Amount of traces used for the test\n", "\n", "\n", "### Do not touch anything from here :)\n", "# Load dataset \n", "ds = utils_files.load_dataset(utils_files.TRAINING_DS[0],seed_shuffle=0, remove_first=True)\n", "\n", "# Compute the labels\n", "pSB = utils_aes.Sbox[ds['pts'] ^ ds['ks']]\n", "\n", "# Compute the PI for the univariate model\n", "results_pi_uni = test_scale.compute_pi_estimations(\n", "    ds['traces'][:-amount_test_traces], \n", "    pSB[:-amount_test_traces], \n", "    ds['traces'][-amount_test_traces:], \n", "    pSB[-amount_test_traces:], \n", "    pi_uni_TA, \n", "    qt_s\n", ")\n", "\n", "# Compute PI for the multivariate model\n", "wrap_pi_LDA_multi_TA = lambda a,b,c,d: pi_LDA_multi_TA(a, b, c, d, npois, ndim)\n", "results_pi_multi = test_scale.compute_pi_estimations(\n", "    ds['traces'][:-amount_test_traces], \n", "    pSB[:-amount_test_traces], \n", "    ds['traces'][-amount_test_traces:], \n", "    pSB[-amount_test_traces:], \n", "    wrap_pi_LDA_multi_TA, \n", "    qt_s\n", ")"]}, {"cell_type": "code", "execution_count": 5, "id": "b7d20e3e-78f2-42d1-befa-1f5d9b8fa881", "metadata": {}, "outputs": [], "source": ["#%matplotlib widget\n", "import matplotlib.pyplot as plt\n", "### Display\n", "byte_indexes= range(16) # Elements in range [0; 15]. Bytes for which display the results.\n", "test_scale.display_IT_results(\n", "    byte_indexes, \n", "    [\n", "        (\"Univariate\",results_pi_uni), \n", "        (\"Multivariate\", results_pi_multi)\n", "    ],\n", "    scale=0.6,\n", "    disable_legend=True\n", ")"]}, {"cell_type": "markdown", "id": "c009c57e-06c7-4d71-853a-6d90059c6911", "metadata": {}, "source": ["To support the conclusion made in the previous point, a legitimate remaining question is whether the model can be further improved by using a higher profiling complexity than the one used. To this end, it is possible to evaluate the amount of information that remains to be learned by a model, as explained in Section 3.3.1, paragraph *Bounding the learnable information*. In particular, the supremum of the PI can be bounded using the Training Information (TI):\n", "\n", "$$\\tilde{\\mathsf{TI}}(V; \\boldsymbol{L}) = \\mathsf{H}(V) + \\sum_{v\\in V}\\mathsf{Pr}(v) \\cdot \\sum_{\\boldsymbol{l}\\in \\mathcal{L}_{\\mathsf{p}}(v)} \\dfrac{1}{|\\mathcal{L}_{\\mathsf{p}}(v)|} \\cdot \\mathsf{log}_{2} \\hat{\\mathsf{Pr}}(v|\\boldsymbol{l}) dl$$\n", "\n", "which in fact corresponds to computing the PI over the training set used to build the model in an overfitted manner. Similarly to what you did for the PI, the following function compute the TI for the univariate and the multivariate models. "]}, {"cell_type": "code", "execution_count": 6, "id": "5d6588a9-5fb2-4e32-9b11-aafcc5b68cd8", "metadata": {}, "outputs": [], "source": ["def ti_uni_TA(train_trs, train_labels):\n", "    \"\"\"\n", "    train_trs: the training traces as an array of shape (train_ntraces, nsamples)\n", "    train_labels: training labels (train_ntraces, nvars)\n", "    return: (tis, lprobs) where\n", "        - `tis` is a vector of shape (n_p,) containing the TI computed for each intermediate state\n", "        - `lprobas` is a matrix of shape (n_p, nb_test) containing the log2 proba used to compute the TI for each of the `n_p' and for each trace.\n", "    \"\"\"\n", "    return pi_uni_TA(train_trs, train_labels, train_trs.copy(), train_labels.copy())\n", "\n", "def ti_LDA_multi_TA(train_trs, train_labels, npois, ndim):\n", "    \"\"\"\n", "    train_trs: the training traces as an array of shape (train_ntraces, nsamples)\n", "    train_labels: training labels (train_ntraces, nvars)\n", "    npois: amount of pois used by the LDA\n", "    ndim: amount of dimensions of the linear subspace projection. \n", "    return: (pis, lprobs) where\n", "        - `pis` is a vector of shape (nvars,) containing the PI computed for each variable\n", "        - `lprobas` is a matrix of shape (nvars, test_ntraces) containing the log2 proba used to compute the PI\n", "    \"\"\"\n", "    return pi_LDA_multi_TA(train_trs, train_labels, train_trs, train_labels, npois, ndim)"]}, {"cell_type": "markdown", "id": "80c2e3b8-3f30-4a0e-b4dc-e97bd5a7e1f6", "metadata": {}, "source": ["In addition to the PI curves you had displayed above, the following code snippets are computing and displaying the corresponding TI. Are they coherent? What can you conclude on the training complexity? Could we expect significantly more information with more traces?"]}, {"cell_type": "code", "execution_count": 7, "id": "7b1e2225-ef8b-4deb-b9ca-9d169a65aa45", "metadata": {}, "outputs": [], "source": ["# Compute the TI with the same configuration than the one used for the PI computationp\n", "results_ti_uni = test_scale.compute_ti_estimations(\n", "    ds['traces'][:-amount_test_traces], \n", "    pSB[:-amount_test_traces], \n", "    ti_uni_TA, \n", "    qt_s\n", ")\n", "\n", "# Compute TI for the multivariate model\n", "wrap_ti_LDA_multi_TA = lambda a,b: ti_LDA_multi_TA(a, b, npois, ndim)\n", "results_ti_multi = test_scale.compute_ti_estimations(\n", "    ds['traces'][:-amount_test_traces], \n", "    pSB[:-amount_test_traces], \n", "    wrap_ti_LDA_multi_TA, \n", "    qt_s\n", ")\n"]}, {"cell_type": "code", "execution_count": 8, "id": "c6b7b0a7-5a76-4622-9b88-862185895cd9", "metadata": {}, "outputs": [], "source": ["### Display\n", "byte_indexes= range(16) # Elements in range [0; 15]. Bytes for which display the results.\n", "test_scale.display_IT_results(\n", "    byte_indexes, \n", "    [\n", "        (\"Univariate\",results_pi_uni), \n", "        (\"Multivariate\", results_pi_multi),\n", "        (\"Univariate\",results_ti_uni),\n", "        (\"Multivariate\", results_ti_multi)\n", "    ],\n", "    scale=0.7,\n", "    disable_legend=True\n", ")"]}, {"cell_type": "markdown", "id": "b519d181-a97e-46fc-a9f1-fabef7280f12", "metadata": {}, "source": ["It turns out that PI/TI metrics are very useful tools when you want to explore the parameter set to find the values that maximize the information exploited. A very useful visual tool are heatmaps, which present the information results obtained for a range of parameters. Here, both PI and TI are displayed for each parameter set explored (respectively as a colored triangle in the bottom left and top right of each box). Try for yourself here! What can you see for a model that lack training traces? \n", "\n", "- *NB: the running time is ~1min per call to `utils_eval.explore_params`, don't hesitate to reduce the set of parameters to speed up the process*"]}, {"cell_type": "code", "execution_count": 19, "id": "a8e8e460-a6a4-428d-9621-58f88ead4045", "metadata": {}, "outputs": [], "source": ["from utils_scale import utils_eval\n", "explo_npois = [8,16,64,256]\n", "explo_ndims = [1,2,4,8]\n", "explo_ntraces_pi = 2048\n", "\n", "# Compute pi/ti\n", "explo_params_bad = utils_eval.explore_params(pi_LDA_multi_TA, ti_LDA_multi_TA, ds['traces'], pSB, explo_ntraces_pi, explo_npois, explo_ndims, qp=4200)\n", "explo_params = utils_eval.explore_params(pi_LDA_multi_TA, ti_LDA_multi_TA, ds['traces'], pSB, explo_ntraces_pi, explo_npois, explo_ndims)"]}, {"cell_type": "code", "execution_count": 20, "id": "02a6e662-39dc-4688-b6c2-7a9bb31227c9", "metadata": {}, "outputs": [], "source": ["utils_eval.make_heatmap(explo_params_bad)\n", "utils_eval.make_heatmap(explo_params)"]}, {"cell_type": "markdown", "id": "9f55d0b3-c285-4efa-bf6c-90f464de226c", "metadata": {}, "source": ["## Histogram-based rank estimation\n", "\n", "It turns out that you already used a common technique to evaluate the quality of different models in the last sections: mounting practical attacks based on the latter and evaluate the attack data complexity achieved! In general, template attacks allow to compute the probabilities $\\hat{\\boldsymbol{p}}_{k_i}$ that contains the probabilities associated to the different subkeys. In our previous examples, $i \\in [0:15]$ and each $\\hat{\\boldsymbol{p}}_{k_i}$ is a vector of length 256 that contains the probabilities associated to every possible values taken by the byte subkey. \n", "\n", "If the correct subkey is always associated to the maximal probability for all subkeys, then the attack is directly successful and does not require to enumerate through potential key candidates. However, the situation may be different in practice, with some subkeys potentially proving more difficult to find than others for a given data complexity. Key enumeration algorithm allows to recombine the $\\hat{\\boldsymbol{p}}_{k_i}$ in order to list all the full key candidates from the most likely to the least likely with the aim of then testing the candidates exhaustively. With such a list, the attacks can be compared based on the position of the correct key in the list (denoted as the rank of the key). \n", "\n", "Computing the exact rank of a key turns out to be challenging since this approach is bounded by the enumeration power of the evaluator. To tackle the issue, rank estimation techniques are efficient algorithm that have been proposed to approximate the rank in an accurate manner. Next, we focus on the histogram-based rank estimation described in Section 2.5.1 and implemented by [SCALib](https://scalib.readthedocs.io/en/stable/source/api/scalib.postprocessing.rankestimation.html#module-scalib.postprocessing.rankestimation). \n", "\n", "We give you next the function `key_rank_approximation_scalib` that estimates the key rank using SCALib. Besides, the following piece of code compare the ranks obtained for the full 128-bit key between the univariate and the multivariate TA you implemented. Considering that you have access to a enumeration power of $2^{32}$, how much traces do you expect to recover the key with high probability using your univariate model? And with your multivariate model?  "]}, {"cell_type": "code", "execution_count": 11, "id": "fafc9767-d0d5-4f0f-92fa-8e07dd8d9e06", "metadata": {}, "outputs": [], "source": ["from scalib.postprocessing import rank_accuracy\n", "import numpy as np\n", "def key_rank_approximation_scalib(subkey_probs, correct_subkeys, max_nb_bin=2**18):\n", "    \"\"\"\n", "    subkey_probs: array of shape (nvars, 256), containing the probabilities associated to the values of 'nvars' subkey bytes.\n", "    correct_subkeys: an array of shape  (nvars,), where the i-th element is the correct value of the i-th subkey. \n", "    return (rmin, r, rmax), where `r` is the approximated rank of the full key, `rmin` and `rmax` are respectively the minimal and maximal bounds.\n", "    \"\"\"\n", "    return rank_accuracy(-np.log(subkey_probs), correct_subkeys, max_nb_bin=max_nb_bin)"]}, {"cell_type": "code", "execution_count": 12, "id": "b34d8d1b-ad44-4c66-ae23-f738fa39f6e5", "metadata": {}, "outputs": [], "source": ["from utils_scale import utils_files, utils_ta\n", "\n", "\n", "\n", "## Run the TA from before\n", "# Dataset used for the training\n", "ds_train = utils_files.TRAINING_DS[0]\n", "\n", "# Datasets on which perform the attack for comparions\n", "ds_atcks = [utils_files.VALIDATION_DS[i] for i in range(5)]\n", "\n", "# Attack complexities\n", "qas = np.arange(1,20)\n", "\n", "# LDAs params (overwrite here if \n", "# you want to use others valeus than the used configured for PI/TI metrics\n", "onpois = npois\n", "ondim = ndim\n", "\n", "# Perform the attack\n", "v_uTA = utils_ta.explore_TA_univariate(ds_train, ds_atcks, None, qas)\n", "v_mTA = utils_ta.explore_TA_multivariate(ds_train, ds_atcks, None, qas, onpois, ondim)\n"]}, {"cell_type": "code", "execution_count": 13, "id": "f0686beb-e614-4779-920f-fa856ebf394c", "metadata": {}, "outputs": [], "source": ["from utils_scale import utils_eval\n", "%matplotlib widget\n", "import matplotlib.pyplot as plt\n", "\n", "byte_indexes = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n", "utils_eval.display_rank_esti_full_key(v_uTA, v_mTA, byte_indexes, key_rank_approximation_scalib)"]}, {"cell_type": "markdown", "id": "6a255de3-cf84-489d-968d-2da02c804b9d", "metadata": {}, "source": ["## Summary question: Univariate Gaussian Template without pooling. \n", "\n", "You now have a set of tools and a good grasp of the concepts needed to answer the last question, which covers all the concepts we have covered in the various tutorials. In particular, how does a univariate TA model without pooling compare with the two models you have already used? What attack complexity can it achieve? For this question, we are volontarily not providing too much information in the template in order for you to go through the full evaluation process by yourself. To make things easier for you, we provide you the profiling phase implementation, which is implemented next. Don't hesitate to re-use part already implemented in the traing!! In particular, try to:\n", "\n", "- Create a new function `pi_uni_TA_nopool` that is a tweaked implementation of `pi_uni_TA` relying on the new modeling phase (i.e., the function `univariate_gaussian_models_nopool`)\n", "- Use `test_scale.compute_pi_estimations` in order to compute the PI values similarly to what was done at the beginning of the session, but using your new function `pi_uni_TA_nopool`.\n", "- Use `test_scale.compute_ti_estimations` in order to compute the TI values similarly to what was done at the beginning of the session, but using your new function `pi_uni_TA_nopool`.\n", "- Use `test_scale.display_IT_results` in order to display the IT metrics together with the other two!\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 14, "id": "fa6d3845-388f-499b-b2e3-c375985d68d8", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "def univariate_gaussian_models_nopool(traces, classes, pois):\n", "    \"\"\"\n", "    traces: the training traces, as an array of shape (ntraces, nsamples).\n", "    classes: the label associated to each variables for every traces, as an array of shape  (ntraces, nvars)\n", "    pois: the single POI kept for each variable, as an array of shape (nvars,)\n", "    \n", "    return: (us, ss), where `us` and `ss` are of shape (nvars, 256) and contain respectively \n", "    the mean and the standard deviation associated every classes of the different variables.\n", "    \"\"\"\n", "    # Allocate return value\n", "    us = np.zeros([classes.shape[1],256])\n", "    ss = np.zeros([classes.shape[1],256])\n", "    \n", "    # Iterate over every variables\n", "    for si in range(classes.shape[1]):\n", "        # Iterate over all the possible bytes values\n", "        for b in range(256):\n", "            # Compute class mean\n", "            us[si,b] = np.mean(traces[classes[:,si] == b, pois[si]])\n", "            # Second, compute the pooled variance\n", "            ss[si,b] = np.std(traces[classes[:,si] == b, pois[si]])\n", "    # Return\n", "    return (us, ss)\n"]}, {"cell_type": "code", "execution_count": 15, "id": "c29bb790-5a39-4c63-ba29-2370351f80c8", "metadata": {}, "outputs": [], "source": ["\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 16, "id": "a703862f-5128-4553-ae99-61d79db0fe38", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "232366c4-bf92-4b51-9560-e89aac3dee3a", "metadata": {}, "source": ["Additionnally, you can also compute the rank in a similar manner that what was done just above. In particular:"]}, {"cell_type": "code", "execution_count": 17, "id": "6a5512cd-0ad5-48dc-a793-b11d8dc0bd91", "metadata": {}, "outputs": [], "source": ["v_uTA_nopool = utils_ta.explore_TA_univariate(ds_train, ds_atcks, None, qas, fn_prof=univariate_gaussian_models_nopool)\n", "from utils_scale import utils_eval\n", "%matplotlib widget\n", "import matplotlib.pyplot as plt\n", "\n", "byte_indexes = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n", "utils_eval.display_rank_esti_full_key(v_uTA, v_uTA_nopool, byte_indexes, key_rank_approximation_scalib)"]}, {"cell_type": "code", "execution_count": null, "id": "223560f7-c863-4d7b-971d-26bda5c8bbbe", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.3"}}, "nbformat": 4, "nbformat_minor": 5}